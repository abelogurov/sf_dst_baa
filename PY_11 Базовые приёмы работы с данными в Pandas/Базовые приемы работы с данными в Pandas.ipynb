{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "\n",
    "# Одним из этапов подготовки данных является удаление, преобразование и создание столбцов таблицы.\n",
    "\n",
    "# Зачем нужны такие манипуляции? \n",
    "\n",
    "# Оказывается, что при правильных преобразованиях таблицы можно добиваться лучшего качества прогноза, \n",
    "# а также извлекать новую информацию из данных и интерпретировать её для заказчика. \n",
    "\n",
    "# Такой подход часто называют Feature Engineering, или генерацией признаков (фичей).\n",
    "\n",
    "# На самом деле, в этом термине заложен более глубокий смысл, \n",
    "# ведь Feature Engineering — это целая методология получения более качественных и более производительных моделей \n",
    "# за счёт манипуляций над данными. Специалисты часто называют данную методологию настоящим искусством, \n",
    "# которое может быть освоено лишь с годами практики решения задач, ведь необходимо быть экспертом в исследуемой предметной области, \n",
    "# чтобы понимать, как признаки влияют друг на друга и какое преобразование стоит к ним применить. \n",
    "\n",
    "# Импортируем Pandas, прочитаем наш csv-файл в DataFrame и выведем первые пять строк таблицы, \n",
    "# чтобы убедиться в том, что файл прочитан верно.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "melb_data = pd.read_csv('data/melb_data_ps.csv', sep=',')\n",
    "melb_data.head()\n",
    "\n",
    "# 2. Базовые операции со столбцами DataFrame\n",
    "# Добавить страницу в мои закладки\n",
    "# СОЗДАНИЕ КОПИИ ТАБЛИЦЫ\n",
    "\n",
    "# На протяжении всего модуля мы будем производить множество тренировочных преобразований с нашей таблицей. \n",
    "# Поэтому, чтобы не переопределять переменную melb_data и тем самым не повредить первоначальный DataFrame, \n",
    "# создадим копию melb_df с помощью метода copy():\n",
    "\n",
    "melb_df = melb_data.copy()\n",
    "melb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# УДАЛЕНИЕ СТОЛБЦОВ\n",
    "\n",
    "# Среди списка базовых операций над столбцами в Pandas важное место занимает возможность удаления столбцов из таблицы. \n",
    "# Это может быть полезно, например, когда в данных есть признаки, которые не несут полезной информации.\n",
    "\n",
    "# Представим, что мы хотим построить модель, которая бы предсказывала цену объекта недвижимости в Мельбурне. \n",
    "# Даже не будучи профессиональными риелторами, мы можем легко сделать следующие выводы:\n",
    "\n",
    "# цена объекта никак не зависит от его порядкового номера (столбец index);\n",
    "# признак, описывающий долготу и широту в виде кортежа Coordinates, дублирует информацию, представленную \n",
    "# в столбцах Longitude и Lattitude.\n",
    "# За удаление строк и столбцов в таблице отвечает метод drop().\n",
    "\n",
    "# Основные параметры метода drop()\n",
    "# Удалим столбцы index и Coordinates из таблицы с помощью метода drop(). Выведем первые пять строк таблицы и убедимся, \n",
    "# что всё прошло успешно.\n",
    "# melb_df = melb_df.drop(['index', 'Coordinates'], axis=1)\n",
    "# melb_df.head()\n",
    "\n",
    "# Альтернативный вариант:\n",
    "melb_df.drop(['index','Coordinates'],axis=1,inplace=True)\n",
    "melb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# МАТЕМАТИЧЕСКИЕ ОПЕРАЦИИ СО СТОЛБЦАМИ\n",
    "\n",
    "# Pandas поддерживает базовые математические операции между столбцами: столбцы можно \n",
    "# складывать, вычитать, умножать, делить между собой, а также возводить в степень. \n",
    "# С помощью таких операций мы можем создавать новые признаки или производить преобразования над старыми.\n",
    "\n",
    "# Причём все операции со столбцами совершаются поэлементно, очень быстро, а самое главное — без написания циклов.\n",
    "\n",
    "# Такая производительность достигается за счёт того, что все математические операции со столбцами выполняются \n",
    "# на языке программирования С, что значительно повышает скорость вычислений по сравнению с перебором элементов в цикле. \n",
    "\n",
    "# Например, давайте создадим переменную total_rooms, в которой будем хранить общее количество комнат в здании. \n",
    "# Для этого выполним сложение столбцов с количеством комнат, ванн и спален:\n",
    "total_rooms = melb_df['Rooms'] + melb_df['Bedroom'] + melb_df['Bathroom']\n",
    "print(total_rooms)\n",
    "\n",
    "# А теперь введём признак MeanRoomsSquare, который соответствует средней площади одной комнаты для каждого объекта. \n",
    "# Для этого разделим площадь здания на полученное ранее общее количество комнат:\n",
    "melb_df['MeanRoomsSquare'] = melb_df['BuildingArea'] / total_rooms\n",
    "print(melb_df['MeanRoomsSquare'])\n",
    "\n",
    "# Можно ввести ещё один интересный признак — AreaRatio, коэффициент соотношения площади здания (BuildingArea) \n",
    "# и площади участка (Landsize). Для этого разницу двух площадей поделим на их сумму:\n",
    "diff_area = melb_df['BuildingArea'] - melb_df['Landsize']\n",
    "sum_area = melb_df['BuildingArea'] + melb_df['Landsize']\n",
    "melb_df['AreaRatio'] = diff_area/sum_area\n",
    "print(melb_df['AreaRatio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 2.3\n",
    "# Напишите функцию delete_columns(df, col=[]), которая удаляет столбцы из DataFrame и возвращает новую таблицу. \n",
    "# Если одного из указанных столбцов не существует в таблице, то функция должна возвращать None. \n",
    "# Удалите выбранные вами столбцы из таблицы customer_df.\n",
    "def delete_columns(df, col=[]):\n",
    "    for cc in col:\n",
    "        if cc not in df.columns:\n",
    "            return None\n",
    "    return df.drop(col, axis=1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    customer_df = pd.DataFrame({\n",
    "        'number': [0, 1, 2, 3, 4],\n",
    "        'cust_id': [128, 1201, 9832, 4392, 7472],\n",
    "        'cust_age': [13, 21, 19, 21, 60],\n",
    "        'cust_sale': [0, 0, 0.2, 0.15, 0.3],\n",
    "        'cust_year_birth': [2008, 2000, 2002, 2000, 1961],\n",
    "        'cust_order': [1400, 14142, 900, 1240, 8430]\n",
    "    })\n",
    "    columns_for_delete= [] #выбранные вами столбцы\n",
    "    new_df = delete_columns(customer_df, columns_for_delete)\n",
    "    print(new_df)\n",
    "\n",
    "# ЗАДАНИЕ 2.4\n",
    "# Задан DataFrame countries_df, содержащий следующие столбцы: название страны, население (population) \n",
    "# в миллионах человек и площадь страны (square) в квадратных километрах.\n",
    "# Рассчитайте среднюю плотность населения представленных стран (количество человек на квадратный километр).\n",
    "countries_df = pd.DataFrame({\n",
    "    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],\n",
    "    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],\n",
    "    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]\n",
    "})\n",
    "countries_df['density'] = countries_df['population'] / countries_df['square'] * 1e6\n",
    "print(round(countries_df['density'].mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Работа с датами в DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРИЗНАКИ ДАТЫ И ВРЕМЕНИ\n",
    "\n",
    "# При генерации новых признаков очень ценным может стать временной признак (признак даты и времени). \n",
    "# Это особый тип данных, с которым приходится сталкиваться в большинстве задач по обработке данных. \n",
    "# В реальных задачах часто нужно сравнивать даты, выделять день недели или час, вычислять различные интервалы между датами. \n",
    "\n",
    "# Например, в наших данных об объектах недвижимости есть признак даты продажи — столбец Date. \n",
    "# Из данного признака можно выделить массу полезной информации, например год, месяц или день недели продажи имущества. \n",
    "# На рынке недвижимости, как известно, присутствует сезонность: есть периоды, когда недвижимость покупается чаще, \n",
    "# а есть интервалы времени, когда рынок претерпевает застой, поэтому было бы неплохо учитывать эту сезонность при анализе рынка.\n",
    "\n",
    "# ФОРМАТ DATETIME\n",
    "\n",
    "# В жизни мы видим даты в привычных для нас форматах. Например, запись 01.12.18 обычно означает 1 декабря 2018 года. \n",
    "# Однако для жителей США эта дата окажется 12 января 2018 года, так как для них привычнее сначала указывать номер месяца, а затем день. \n",
    "\n",
    "# Многие выгрузки из систем и баз данных имеют свой служебный формат. Например, формат времени из разных систем может отличаться:\n",
    "\n",
    "# 2018-11-09 15:45:21;\n",
    "# 11/09/2018 3:45:20 PM;\n",
    "# 2018-11-09T15:45:21.2984.\n",
    "# Для всех этих случаев необходимо задавать формат распознавания дат и уметь сравнивать их между собой. \n",
    "# Для этого был создан единый способ обозначения даты и времени. \n",
    "\n",
    "# Таким форматом в Pandas является формат datetime, который записывается как YYYY-MM-DD HH: MM: SS, \n",
    "# то есть составляющие времени указываются в следующем порядке: год, месяц, день, час, минута, секунда.\n",
    "\n",
    "# В наших данных дата записана в виде DD/MM/YYYY, например 3/12/2017. Посмотрим на это:\n",
    "print(melb_df['Date'])\n",
    "\n",
    "# Для того чтобы преобразовывать столбцы с датами, записанными в распространённых форматах,\n",
    "# в формат datetime, можно воспользоваться функцией pandas.to_datetime(). \n",
    "# В нашем случае в функции нужно указать параметр dayfirst=True, который будет обозначать, \n",
    "# что в первоначальном признаке первым идет день. Преобразуем столбец Date в формат datetime, передав его в эту функцию:\n",
    "melb_df['Date'] = pd.to_datetime(melb_df['Date'], dayfirst=True)\n",
    "print(melb_df['Date'])\n",
    "\n",
    "# В результате мы переопределяем признак Date в формат datetime. \n",
    "# При этом так как в изначальном варианте время не было указано, то и после преобразования оно опускается.\n",
    "\n",
    "# Стоит обратить внимание, что изменился тип данных для столбца Date, теперь его тип — datetime64. \n",
    "# Рассмотрим несколько возможностей этого типа данных.\n",
    "\n",
    "# ВЫДЕЛЕНИЕ АТРИБУТОВ DATETIME\n",
    "\n",
    "# Тип данных datetime позволяет с помощью специального аксессора dt выделять составляющие времени из каждого элемента столбца, \n",
    "# такие как:\n",
    "\n",
    "# date — дата;\n",
    "# year, month, day — год, месяц, день;\n",
    "# time — время;\n",
    "# hour, minute, second — час, минута, секунда;\n",
    "# dayofweek — номер дня недели, от 0 до 6, где 0 — понедельник, 6 — воскресенье;\n",
    "# day_name — название дня недели;\n",
    "# dayofyear — порядковый день года;\n",
    "# quarter — квартал (интервал в три месяца).\n",
    "\n",
    "# Например, обратившись по атрибуту dt.year в столбце Date, мы можем «достать» год продажи и понять, \n",
    "# за какой интервал времени (в годах) представлены наши данные, а также на какой год приходится наибольшее число продаж:\n",
    "years_sold = melb_df['Date'].dt.year\n",
    "print(years_sold)\n",
    "print('Min year sold:', years_sold.min())\n",
    "print('Max year sold:', years_sold.max())\n",
    "print('Mode year sold:', years_sold.mode()[0])\n",
    "\n",
    "# В результате обращения к атрибуту datetime melb_df['Date'].dt.year мы получаем объект Series, \n",
    "# в котором в качестве значений выступают годы продажи объектов недвижимости. Мы можем занести результат \n",
    "# в переменную year_sold и далее работать с ней как с обычным столбцом Series — вычислять максимум, минимум и модальное значение.\n",
    "\n",
    "# Из результатов видно, что данные представлены за интервал с 2016 по 2017 год и наибольшее количество объектов было продано в 2017 году.\n",
    "\n",
    "# Примечание. Так как модальных значений в столбце может быть несколько, метод mode() возвращает объект Series, \n",
    "# даже если мода в данных только одна. Чтобы сохранить стилистику вывода информации о годе продажи и выводить только число,\n",
    "# а не Series, мы обращаемся к результату работы метода mode() по индексу 0.\n",
    "\n",
    "# Теперь попробуем понять, на какие месяцы приходится пик продаж объектов недвижимости. \n",
    "# Для этого выделим атрибут dt.month и на этот раз занесём результат в столбец MonthSale, \n",
    "# а затем найдём относительную частоту продаж для каждого месяца от общего количества продаж — для этого используем метод value_counts() \n",
    "# с параметром normalize (вывод в долях):\n",
    "melb_df['MonthSale'] = melb_df['Date'].dt.month\n",
    "melb_df['MonthSale'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# РАБОТА С ИНТЕРВАЛАМИ\n",
    "\n",
    "# Часто бывает такая ситуация, что необходимо вычислять интервалы между двумя временными промежутками. \n",
    "# Например, можно вычислить, сколько дней прошло с 1 января 2016 года до момента продажи объекта. \n",
    "# Для этого можно просто найти разницу между датами продаж и заявленной датой, представленной в формате datetime:\n",
    "delta_days = melb_df['Date'] - pd.to_datetime('2016-01-01') \n",
    "print(delta_days)\n",
    "\n",
    "# В результате мы получаем Series, элементами которой является количество дней, \n",
    "# которое прошло с 1 января 2016 года. Обратите внимание, что данные такого формата относятся к типу timedelta.\n",
    "\n",
    "# Чтобы превратить количество дней из формата интервала в формат целого числа дней, \n",
    "# можно воспользоваться аксессором dt для формата timedelta и извлечь из него атрибут days:\n",
    "print(delta_days.dt.days)\n",
    "\n",
    "# Рассмотрим другой пример. Давайте создадим признак возраста объекта недвижимости в годах на момент продажи. \n",
    "# Для этого выделим из столбца с датой продажи год и вычтем из него год постройки здания. \n",
    "# Результат оформим в виде столбца AgeBuilding:\n",
    "melb_df['AgeBuilding'] = melb_df['Date'].dt.year - melb_df['YearBuilt']\n",
    "print(melb_df['AgeBuilding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.3\n",
    "# Создайте в таблице melb_df признак WeekdaySale (день недели). \n",
    "# Найдите, сколько объектов недвижимости было продано в выходные (суббота и воскресенье), \n",
    "# результат занесите в переменную weekend_count. В качестве ответа введите результат вывода переменной weekend_count.\n",
    "melb_df['WeekdaySale'] = melb_df['Date'].dt.dayofweek\n",
    "weekend_count = melb_df[(melb_df['WeekdaySale'] == 5) | (melb_df['WeekdaySale'] == 6)].shape[0]\n",
    "print(weekend_count)\n",
    "\n",
    "# ЗАДАНИЕ 3.4\n",
    "# В каком году отмечается наибольшее количество случаев наблюдения НЛО в США?\n",
    "df = pd.read_csv('http://bit.ly/uforeports')\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "print(df['Time'].dt.year.mode()[0])\n",
    "\n",
    "# ЗАДАНИЕ 3.5\n",
    "# Найдите средний интервал времени (в днях) между двумя последовательными случаями наблюдения НЛО в штате Невада (NV).\n",
    "df['Date'] = df['Time'].dt.date\n",
    "print(df[df['State']=='NV']['Date'].diff().dt.days.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Создание и преобразование столбцов с помощью функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека Pandas предоставляет большое количество возможностей для преобразований данных, \n",
    "# однако иногда необходимо совершать более сложные манипуляции над столбцами. \n",
    "# Например, из столбцов, содержащих в себе некоторый текст, необходимо специальным образом извлечь определённые слова, даты или числа.\n",
    "\n",
    "# Для таких случаев Pandas не имеет специальных методов, однако позволяет расширить свою функциональность \n",
    "# за счёт использования пользовательских функций. \n",
    "\n",
    "# Мы можем написать некоторую функцию, которая принимает на вход один элемент столбца, \n",
    "# каким-то образом его обрабатывает и возвращает результат, после чего применить \n",
    "# эту функцию к каждому элементу в столбце с помощью специального метода apply(). \n",
    "# В результате применения этой функции будет возвращён объект Series, \n",
    "# элементы которого будут представлять результат работы этой функции.\n",
    "\n",
    "# Рассмотрим пример. В наших данных есть столбец с адресами объектов недвижимости. \n",
    "# Проблема этого столбца в том, что в нём слишком большое количество уникальных значений: \n",
    "# почти на каждый объект недвижимости в таблице приходится свой уникальный адрес. \n",
    "# Убедимся в этом, вычислив количество уникальных значений в столбце с помощью метода nunique():\n",
    "print(melb_df['Address'].nunique())\n",
    "\n",
    "# Если мы прогнозируем цену объекта, то такое большое количество возможных категорий может плохо сказаться на модели, \n",
    "# которую мы бы хотели в дальнейшем построить на наших данных. \n",
    "# Говорят, что такой признак, скорее всего, не имеет статистической значимости, \n",
    "# потому что не позволяет разделить данные на группы, которые можно сравнить по целевому признаку.\n",
    "\n",
    "# Из-за таких признаков зависимость между целевым признаком, который мы хотим предсказать, \n",
    "# и признаками, на основе которых мы делаем предсказание, становится очень сложной. \n",
    "# При этом точность моделирования при учёте такого признака может не повыситься, а даже снизиться, \n",
    "# а производительность однозначно резко упадёт.\n",
    "\n",
    "# Обычно подобные признаки удаляют, однако можно поступить умнее: \n",
    "# давайте извлечём из признака адреса характеристику подтипа улицы (улица, шоссе, авеню, бульвар). \n",
    "# Для этого сначала внимательнее посмотрим на структуру адреса, выберем несколько строк столбца Address:\n",
    "print(melb_df['Address'].loc[177])\n",
    "print(melb_df['Address'].loc[1812])\n",
    "print(melb_df['Address'].loc[9001])\n",
    "\n",
    "# Итак, адрес строится следующим образом: сначала указывается номер дома и корпус, \n",
    "# после указывается название улицы, а в конце — подтип улицы, но в некоторых случаях \n",
    "# к подтипу добавляется географическая отметка (N — север, S — юг и т. д.), она нам не нужна. \n",
    "# Для того чтобы выделить подтип улицы, на которой находится объект, можно использовать следующую функцию:\n",
    "\n",
    "# На вход данной функции поступает строка с адресом.\n",
    "def get_street_type(address):\n",
    "# Создаём список географических пометок exclude_list.\n",
    "    exclude_list = ['N', 'S', 'W', 'E']\n",
    "# Метод split() разбивает строку на слова по пробелу.\n",
    "# В результате получаем список слов в строке и заносим его в переменную address_list.\n",
    "    address_list = address.split(' ')\n",
    "# Обрезаем список, оставляя в нём только последний элемент,\n",
    "# потенциальный подтип улицы, и заносим в переменную street_type.\n",
    "    street_type = address_list[-1]\n",
    "# Делаем проверку на то, что полученный подтип является географической пометкой.\n",
    "# Для этого проверяем его на наличие в списке exclude_list.\n",
    "    if street_type in exclude_list:\n",
    "# Если переменная street_type является географической пометкой,\n",
    "# переопределяем её на второй элемент с конца списка address_list.\n",
    "        street_type = address_list[-2]\n",
    "# Возвращаем переменную street_type, в которой хранится подтип улицы.\n",
    "    return street_type\n",
    "\n",
    "# ДОПОЛНИТЕЛЬНО\n",
    "\n",
    "# Подробнее о методе split()\n",
    "\n",
    "# Теперь применим эту функцию к столбцу c адресом. Для этого передадим функцию get_street_type в аргумент метода столбца apply(). \n",
    "# В результате получим объект Series, который положим в переменную street_types:\n",
    "street_types = melb_df['Address'].apply(get_street_type)\n",
    "print(street_types)\n",
    "\n",
    "# Обратите внимание, что функция пишется для одного элемента столбца, а метод apply() применяется к каждому его элементу.\n",
    "# Используемая функция обязательно должна иметь возвращаемое значение.\n",
    "\n",
    "# Итак, мы смогли выделить подтип улицы. Посмотрим, сколько уникальных значений у нас получилось:\n",
    "print(street_types.nunique())\n",
    "\n",
    "# У нас есть 56 уникальных значений. Однако наш результат можно улучшить. \n",
    "# Давайте для начала посмотрим на частоту каждого подтипа улицы с помощью метода value_counts:\n",
    "print(street_types.value_counts())\n",
    "\n",
    "# Из данного вывода можно увидеть, что есть группа наиболее популярных подтипов улиц, а дальше частота подтипов быстро падает.\n",
    "\n",
    "# В таком случае давайте применим очень распространённый метод уменьшения количества \n",
    "# уникальных категорий — выделим n подтипов, которые встречаются чаще всего, а остальные обозначим как 'other' (другие).\n",
    "\n",
    "# Для этого к результату метода value_counts применим метод nlargest(), \n",
    "# который возвращает n наибольших значений из Series. Зададим n=10, \n",
    "# т. е. мы хотим отобрать десять наиболее популярных подтипов. Извлечём их названия с помощью атрибута index, \n",
    "# а результат занесём в переменную popular_stypes:\n",
    "popular_stypes =street_types.value_counts().nlargest(10).index\n",
    "print(popular_stypes)\n",
    "\n",
    "# Попробуйте применить использованные методы последовательно и выводить результат, чтобы проследить за логикой преобразования.\n",
    "\n",
    "# Теперь, когда у нас есть список наиболее популярных подтипов улиц, введём lambda-функцию, которая будет проверять, \n",
    "# есть ли строка x в этом перечне, и, если это так, lambda-функция будет возвращать x, \n",
    "# в противном случае она будет возвращать строку 'other'. Наконец, применим такую функцию к Series street_types, \n",
    "# полученной ранее, а результат определим в новый столбец таблицы StreetType:\n",
    "melb_df['StreetType'] = street_types.apply(lambda x: x if x in popular_stypes else 'other')\n",
    "print(melb_df['StreetType'])\n",
    "\n",
    "# Посмотрим на результирующее число уникальных подтипов:\n",
    "print(melb_df['StreetType'].nunique())\n",
    "\n",
    "# Теперь, у нас нет потребности хранить признак Address, так как, \n",
    "# если конкретное местоположение объекта всё же и влияет на его стоимость, \n",
    "# то оно определяется столбцами Longitude и Lattitude. Удалим его из нашей таблицы:\n",
    "melb_df = melb_df.drop('Address', axis=1)\n",
    "\n",
    "# Таким образом, с помощью написания собственных функций и их комбинирования с методом apply() \n",
    "# из библиотеки Pandas мы смогли извлечь информацию из признака с адресом и заменить на признак подтипа улицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 4.2\n",
    "# Ранее, в задании 3.3, мы создали признак WeekdaySale в таблице melb_df — день недели продажи. \n",
    "# Из полученных в задании результатов можно сделать вывод, что объекты недвижимости в Мельбурне \n",
    "# продаются преимущественно по выходным (суббота и воскресенье).\n",
    "# Напишите функцию get_weekend(weekday), которая принимает на вход элемент столбца WeekdaySale и возвращает 1, \n",
    "# если день является выходным, и 0 — в противном случае, и создайте столбец Weekend в таблице melb_df с помощью неё.\n",
    "\n",
    "# Примените эту функцию к столбцу и вычислите среднюю цену объекта недвижимости, проданного в выходные дни. \n",
    "# Результат округлите до целых.\n",
    "def get_weekend(weekday):\n",
    "    if weekday == 5 or weekday == 6:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "melb_df['Weekend'] = melb_df['WeekdaySale'].apply(get_weekend)\n",
    "print(round(melb_df[melb_df['Weekend']==1]['Price'].mean(), 2))\n",
    "\n",
    "# ЗАДАНИЕ 4.3\n",
    "# Преобразуйте столбец SellerG с наименованиями риелторских компаний в таблице melb_df следующим образом: \n",
    "# оставьте в столбце только 49 самых популярных компаний, а остальные обозначьте как 'other'.\n",
    "# Найдите, во сколько раз минимальная цена объектов недвижимости, проданных компанией 'Nelson', \n",
    "# больше минимальной цены объектов, проданных компаниями, обозначенными как 'other'. Ответ округлите до десятых.\n",
    "popular_seler = melb_df['SellerG'].value_counts().nlargest(49).index\n",
    "# заменяем значения улиц, не попавших в список популярных на строку 'other'\n",
    "melb_df['SellerG'] = melb_df['SellerG'].apply(lambda x: x if x in popular_seler else 'other') \n",
    "a = melb_df[melb_df['SellerG'] == 'Nelson']['Price'].min() \n",
    "b = melb_df[melb_df['SellerG'] == 'other']['Price'].min() \n",
    "print(round(a/b, 1))\n",
    "\n",
    "# ЗАДАНИЕ 4.4\n",
    "# Представьте, что вы занимаетесь подготовкой данных о вакансиях с платформы hh.ru.\n",
    "# В вашем распоряжении имеется таблица, в которой с помощью парсинга собраны резюме кандидатов. \n",
    "# В этой таблице есть текстовый столбец «Опыт работы». Пример такого столбца представлен ниже в виде объекта Series. \n",
    "# Структура текста в столбце фиксирована и не может измениться.\n",
    "\n",
    "# Напишите функцию get_experience(arg), аргументом которой является строка столбца с опытом работы. \n",
    "# Функция должна возвращать опыт работы в месяцах. Не забудьте привести результат к целому числу.\n",
    "def get_experience(arg):\n",
    "    month_key_words = ['месяц', 'месяцев', 'месяца']\n",
    "    year_key_words = ['год', 'лет', 'года']\n",
    "    args_splited = arg.split(' ')\n",
    "    month = 0\n",
    "    year = 0\n",
    "    for i in range(len(args_splited)):\n",
    "        if args_splited[i] in month_key_words:\n",
    "            month = args_splited[i-1]\n",
    "        if args_splited[i] in year_key_words:\n",
    "            year = args_splited[i-1]\n",
    "    return int(year)*12 + int(month)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experience_col = pd.Series([\n",
    "        'Опыт работы 8 лет 3 месяца',\n",
    "        'Опыт работы 3 года 5 месяцев',\n",
    "        'Опыт работы 1 год 9 месяцев',\n",
    "        'Опыт работы 3 месяца',\n",
    "        'Опыт работы 6 лет'\n",
    "        ])\n",
    "    experience_month = experience_col.apply(get_experience)\n",
    "    print(experience_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Тип данных Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важной частью предобработки данных является оптимизация хранения данных и работы с ними. \n",
    "# В этом разделе мы поговорим об оптимизации работы с категориальными признаками.\n",
    "\n",
    "# ПРИЗНАКИ: КАТЕГОРИАЛЬНЫЕ И ЧИСЛОВЫЕ\n",
    "\n",
    "# Рассмотрим такие статистические термины, как категориальные и числовые признаки.\n",
    "\n",
    "# Под числовыми признаками обычно подразумевают признаки, которые отражают количественную меру и могут принимать значения \n",
    "# из неограниченного диапазона.\n",
    "\n",
    "# Числовые признаки могут быть:\n",
    "\n",
    "# дискретными (например, количество комнат, пациентов, дней, отток сотрудников);\n",
    "# непрерывными (например, масса, цена, площадь).\n",
    "# Дискретные признаки чаще всего представлены целыми числами, а непрерывные — целыми числами и числами с плавающей точкой.\n",
    "\n",
    "# Под категориальными признаками обычно подразумевают столбцы в таблице, которые обозначают принадлежность\n",
    "# объекта к какому-то классу/категории.\n",
    "\n",
    "# Категориальные признаки могут быть:\n",
    "\n",
    "# номинальными (например, пол, национальность, район);\n",
    "# порядковыми (например, уровень образования, уровень комфорта, стадия заболевания).\n",
    "# Такие признаки имеют ограниченный набор значений. Они чаще всего представлены в виде текстового описания \n",
    "# и кодируются в Pandas типом данных object.\n",
    "\n",
    "# Однако это не всегда так. Например, созданный нами ранее признак месяца продажи кодируется \n",
    "# числом (от 1 до 12), но на самом деле является категориальным, поскольку диапазон его значений ограничен \n",
    "# и каждому числу мы можем поставить в соответствие название месяца.\n",
    "\n",
    "# Возникает вопрос: а какие признаки стоит считать категориальными?\n",
    "\n",
    "# Однозначного ответа на этот вопрос нет. Решение, какой признак отнести к классу категорий, \n",
    "# остаётся за исследователем. Некоторые специалисты даже относят количественные признаки в разряд категориальных, \n",
    "# когда диапазон возможных значений довольно мал. \n",
    "\n",
    "# Не существует жёсткого правила, определяющего, сколько значений должна иметь категориальная переменная. \n",
    "# Вы должны использовать собственные знания о предметной области, чтобы сделать выбор. \n",
    "# Однако в этом разделе мы всё же введём некоторые рекомендации.\n",
    "\n",
    "# ДОПОЛНИТЕЛЬНО\n",
    "\n",
    "# На самом деле классификация признаков уходит даже глубже — здесь вы сможете подробнее ознакомиться со всеми тонкостями.\n",
    "\n",
    "# ПОЧЕМУ ТАК ВАЖНО ОТЛИЧАТЬ КАТЕГОРИАЛЬНЫЕ СТОЛБЦЫ ОТ ДРУГИХ?\n",
    "\n",
    "# Оказывается, анализ и предобработка категориальных признаков отличается от предобработки числовых признаков.\n",
    "\n",
    "# Мы уже видели, что в столбцах с типом данных object мы не можем рассчитать среднее значение, \n",
    "# стандартное отклонение или другие статистические параметры, которые годятся только для чисел.\n",
    "\n",
    "# Способ заполнения пропущенных данных и поиск аномальных значений также различаются для разных типов признаков, \n",
    "# но этот момент мы рассмотрим в модуле по очистке данных.\n",
    "\n",
    "# КАТЕГОРИИ В ДАННЫХ О НЕДВИЖИМОСТИ\n",
    "\n",
    "# Давайте определим число уникальных категорий в каждом столбце нашей таблицы melb_df. \n",
    "# Для этого создадим вспомогательную таблицу unique_counts:\n",
    "\n",
    "# создаём пустой список\n",
    "unique_list = []\n",
    "# пробегаемся по именам столбцов в таблице\n",
    "for col in melb_df.columns:\n",
    "    # создаём кортеж (имя столбца, число уникальных значений)\n",
    "    item = (col, melb_df[col].nunique(),melb_df[col].dtype) \n",
    "    # добавляем кортеж в список\n",
    "    unique_list.append(item) \n",
    "# создаём вспомогательную таблицу и сортируем её\n",
    "unique_counts = pd.DataFrame(\n",
    "    unique_list,\n",
    "    columns=['Column_Name', 'Num_Unique', 'Type']\n",
    ").sort_values(by='Num_Unique',  ignore_index=True)\n",
    "# выводим её на экран\n",
    "print(unique_counts)\n",
    "\n",
    "\n",
    "# Разберём код подробнее:\n",
    "\n",
    "# 1\n",
    "# Создаём пустой список, в который будем добавлять кортежи: имя столбца, количество уникальных значений в нём и тип столбца.\n",
    "\n",
    "# 2\n",
    "# В цикле перебираем имена столбцов, которые получаем с помощью атрибута columns. \n",
    "# В переменной col на каждой итерации находятся имена столбцов — обращаемся к ним в цикле и извлекаем число уникальных \n",
    "# элементов с помощью метода nunique(), а также тип столбца с помощью атрибута dtypes. \n",
    "# Результат заносим в кортеж и добавляем его в список.\n",
    "\n",
    "# 3\n",
    "# Из списка с кортежами (имя столбца, количество уникальных значений в нём, тип столбца) с\n",
    "# оздаём DataFrame, даём названия его столбцам: Column_Name, Num_unique и Type.\n",
    "\n",
    "# 4\n",
    "# Сортируем таблицу по столбцу Num_unique в порядке возрастания количества уникальных элементов \n",
    "# с помощью метода sort_values() и выводим результат на экран.\n",
    "\n",
    "# Примечание. Мы ещё не изучали сортировку DataFrame методом sort_values() — данную тему мы обсудим в следующем модуле, \n",
    "# однако здесь эта функция необходима для более наглядной интерпретации результата.\n",
    "\n",
    "# Итак, с помощью такого несложного кода мы смогли получить вспомогательную таблицу, \n",
    "# где в отсортированном виде показано количество уникальных значений во всех столбцах и их типы.\n",
    "\n",
    "# Что интересного мы можем узнать из такой таблицы?\n",
    "\n",
    "# Если присмотреться внимательно, можно увидеть резкий скачок количества уникальных значений, начиная с 14 строки таблицы, \n",
    "# где число уникальных значений составляет 152. Учтём этот момент.\n",
    "\n",
    "# Условимся, что категориальными будем считать признаки, у которых число уникальных категорий меньше 150. \n",
    "\n",
    "# Однако учтём, что признак Date (дата продажи), преобразованный нами ранее в формат datetime, является временным признаком,\n",
    "# поэтому далее не будем его воспринимать как категориальный. \n",
    "\n",
    "# К тому же в наш потенциальный список попали количественные столбцы Rooms, Car, Bedroom и Bathroom. \n",
    "# Договоримся, что мы не будем относить их к разряду категориальных, однако, как упоминалось ранее, такое тоже вполне возможно.\n",
    "\n",
    "# Примечание. Ещё раз подчеркиваем, что такая классификация признаков является исключительно субъективной и специфична для задачи.\n",
    "\n",
    "# ТИП ДАННЫХ CATEGORY\n",
    "\n",
    "# Для хранения и оптимизации работы с категориальными признаками в Pandas предусмотрен специальный тип данных — category.\n",
    "\n",
    "# Этот тип данных является гибридным: внешне он выглядит как строка, но внутренне представлен массивом целых чисел. \n",
    "# Так как данные вместо изначальных строк хранятся в памяти как число, то объём памяти, \n",
    "# занимаемой таблицей при использовании типа category, резко уменьшается, что повышает эффективность хранения и работы с таблицей.\n",
    "\n",
    "# Более того, этот тип данных расширяет возможности работы с категориальными признаками: мы можем легко преобразовывать категории, \n",
    "# строить графики по таким данным (что сложно сделать для типа данных object). Также резко повышается производительность операций, \n",
    "# совершаемых с такими столбцами.\n",
    "\n",
    "# Самый простой способ преобразования столбцов к типу данных category — это использование уже знакомого нам метода astype(), \n",
    "# в параметры которого достаточно передать строку 'category'.\n",
    "\n",
    "# Рассмотрим это на примере.\n",
    "\n",
    "# Для начала, выведем информацию о памяти, занимаемой текущей таблицей, с помощью метода info():\n",
    "print(melb_df.info())\n",
    "\n",
    "# Примечание. \n",
    "# Объём занимаемой памяти и количество столбцов на вашем компьютере может отличаться в зависимости от того,\n",
    "# выполняли ли вы код и задания из предыдущих разделов на добавление и преобразование данных в таблице.\n",
    "\n",
    "# Сделаем преобразование столбцов к типу данных category:\n",
    "cols_to_exclude = ['Date', 'Rooms', 'Bedroom', 'Bathroom', 'Car'] # список столбцов, которые мы не берём во внимание\n",
    "max_unique_count = 150 # задаём максимальное число уникальных категорий\n",
    "for col in melb_df.columns: # цикл по именам столбцов\n",
    "    if melb_df[col].nunique() < max_unique_count and col not in cols_to_exclude: # проверяем условие\n",
    "        melb_df[col] = melb_df[col].astype('category') # преобразуем тип столбца\n",
    "print(melb_df.info())\n",
    "\n",
    "# Разберём код подробнее:\n",
    "\n",
    "# 1\n",
    "# Задаём список столбцов, которые мы не берём в рассмотрение (cols_to_exclude), \n",
    "# а также условленный нами ранее порог уникальных значений столбца max_unique_count.\n",
    "\n",
    "# 2\n",
    "# В цикле перебираем имена столбцов, и, если число уникальных категорий меньше заданного порога \n",
    "# и имён столбцов нет в списке cols_to_exclude, то с помощью метода astype() приводим столбец к типу данных category.\n",
    "\n",
    "# 3\n",
    "# Итоговый объём памяти — 1.9 Мб. \n",
    "# В результате такого преобразования объём памяти, занимаемый таблицей, уменьшился почти в 1.5 раза. Это впечатляет!\n",
    "\n",
    "# Особенно хорошо такое преобразование работает на действительно больших данных, \n",
    "# где число строк превышает сотни тысяч или миллионы. Иногда изменение типов может уменьшить объём памяти \n",
    "# в десятки раз и существенно увеличить производительность.\n",
    "\n",
    "# ПОЛУЧЕНИЕ АТРИБУТОВ CATEGORY\n",
    "\n",
    "# У типа данных category есть свой специальный аксесcор cat, который позволяет получать информацию \n",
    "# о своих значениях и преобразовывать их. \n",
    "# Например, с помощью атрибута этого аксессора categories мы можем получить список уникальных категорий в столбце Regionname:\n",
    "print(melb_df['Regionname'].cat.categories)\n",
    "\n",
    "# А теперь посмотрим, каким образом столбец кодируется в виде чисел в памяти компьютера. \n",
    "# Для этого можно воспользоваться атрибутом codes:\n",
    "print(melb_df['Regionname'].cat.codes)\n",
    "\n",
    "# С помощью метода аксессора rename_categories() можно легко переименовать текущие значения категорий. \n",
    "# Для этого в данный метод нужно передать словарь, ключи которого — старые имена категорий, а значения — новые.\n",
    "\n",
    "# Рассмотрим на примере: переименуем категории признака типа постройки \n",
    "# Type — заменим их на полные названия (напомним, u — unit, h — house, t — townhouse).\n",
    "melb_df['Type'] = melb_df['Type'].cat.rename_categories({\n",
    "    'u': 'unit',\n",
    "    't': 'townhouse',\n",
    "    'h': 'house'\n",
    "})\n",
    "print(melb_df['Type'])\n",
    "\n",
    "# ДОПОЛНИТЕЛЬНО\n",
    "\n",
    "# Подробнее ознакомиться с другими возможностями типа данных category можно здесь.\n",
    "\n",
    "# ПОДВОДНЫЕ КАМНИ\n",
    "\n",
    "# А теперь представим ситуацию, что появилась новая партия домов и теперь мы продаём и квартиры (flat). \n",
    "# Создадим объект Series new_houses_types, в котором будем хранить типы зданий новой партии домов. \n",
    "# Преобразуем тип new_houses_types в такой же тип, как и у столбца Type в таблице melb_data, и выведем результат на экран:\n",
    "new_houses_types = pd.Series(['unit', 'house', 'flat', 'flat', 'house'])\n",
    "new_houses_types = new_houses_types.astype(melb_df['Type'].dtype)\n",
    "print(new_houses_types)\n",
    "\n",
    "# С нашими новыми объектами недвижимости произошло нечто странное. \n",
    "# По какой-то причине вместо квартир мы получили пустые значения — NaN.\n",
    "\n",
    "# На самом деле причина проста: тип данных category хранит только категории, которые были объявлены при его инициализации. \n",
    "# При встрече с новой, неизвестной ранее категорией, этот тип превратит её в пустое значение, \n",
    "# так как он просто не знает о существовании этой категории.\n",
    "\n",
    "# Решить эту проблему на самом деле не сложно. \n",
    "# Можно добавить категорию flat в столбец Type с помощью метода акссесора cat add_categories(), \n",
    "# в который достаточно просто передать имя новой категории:\n",
    "melb_df['Type'] = melb_df['Type'].cat.add_categories('flat')\n",
    "new_houses_types = pd.Series(['unit', 'house', 'flat', 'flat', 'house'])\n",
    "new_houses_types = new_houses_types.astype(melb_df['Type'].dtype)\n",
    "print(new_houses_types)\n",
    "\n",
    "# Примечание. \n",
    "# Добавление новой категории в столбец Type не отразится на самом столбце — текущие категории не изменятся, \n",
    "# однако такое преобразование позволит добавлять в таблицу новые данные о домах с новой категорией — flat.\n",
    "\n",
    "# Из данного примера можно сделать вывод, что если набор категорий в столбце жёстко не зафиксирован и может \n",
    "# обновляться в процессе работы, то тип category не является подходящим типом данных для этого столбца или необходимо \n",
    "# постоянно писать проверки при обновлении таблицы.\n",
    "\n",
    "# Теперь, когда мы рассмотрели основные моменты и нюансы работы с типом данных category, \n",
    "# можно сформулировать несколько рекомендаций по его использованию:\n",
    "\n",
    "# 1\n",
    "# Необязательно каждый раз преобразовывать категориальные данные в тип данных category. \n",
    "# Зачастую это делается исключительно для оптимизации работы с большими данными.\n",
    "\n",
    "# 2\n",
    "# Если набор данных занимает значительный процент используемой оперативной памяти, \n",
    "# рассмотрите возможность использования типа category.\n",
    "\n",
    "# 3\n",
    "# Если у вас очень серьёзные проблемы с производительностью, обратите внимание на использование типа category.\n",
    "\n",
    "# 4\n",
    "# Если вы решили использовать тип category, будьте осторожны при добавлении новой информации в вашу таблицу. \n",
    "# Убедитесь, что вы собрали всю необходимую информацию, произведите предобработку данных \n",
    "# и только после этого используйте преобразование типов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/citibike-tripdata.csv', sep=',')\n",
    "\n",
    "# ЗАДАНИЕ 6.3\n",
    "# Найдите идентификатор самой популярной стартовой стоянки. Запишите идентификатор в виде целого числа.\n",
    "print(data['start station id'].mode()[0])\n",
    "\n",
    "# ЗАДАНИЕ 6.4\n",
    "# Велосипед с каким идентификатором является самым популярным?\n",
    "print(data['bikeid'].mode()[0])\n",
    "\n",
    "# ЗАДАНИЕ 6.5\n",
    "# Какой тип клиентов (столбец usertype) является преобладающим — Subscriber или Customer? \n",
    "# В качестве ответа запишите долю клиентов преобладающего типа среди общего количества клиентов. Ответ округлите до сотых.\n",
    "mode_usertype = data['usertype'].mode()[0]\n",
    "count_mode_user = data[data['usertype'] == mode_usertype].shape[0]\n",
    "print(round(count_mode_user / data.shape[0], 2))\n",
    "\n",
    "# ЗАДАНИЕ 6.6\n",
    "# Кто больше занимается велоспортом — мужчины или женщины? В ответ запишите число поездок для той группы, у которой их больше.\n",
    "male_count = data[data['gender'] == 1].shape[0]\n",
    "female_count = data[data['gender'] == 0].shape[0]\n",
    "print(max([male_count, female_count]))\n",
    "\n",
    "# ЗАДАНИЕ 6.8\n",
    "# В первую очередь удалим лишнюю информацию из данных.\n",
    "# В наших данных присутствуют столбцы, которые дублируют информацию друг о друге:\n",
    "# это столбцы с идентификатором и названием стартовой и конечной стоянки. \n",
    "# Удалите признаки идентификаторов стоянок. Сколько столбцов осталось?\n",
    "data.drop(['start station id', 'end station id'], axis=1, inplace=True)\n",
    "print(data.shape[1])\n",
    "\n",
    "# ЗАДАНИЕ 6.9\n",
    "# Замените признак birth year на более понятный признак возраста клиента age. Годом отсчёта возраста выберите 2018 год. \n",
    "# Столбец birth year удалите из таблицы. Сколько поездок совершено клиентами старше 60 лет?\n",
    "data['age'] = 2018 - data['birth year']\n",
    "data.drop(['birth year'], axis=1, inplace=True)\n",
    "print(data[data['age'] > 60].shape[0])\n",
    "\n",
    "# ЗАДАНИЕ 6.10\n",
    "# Создайте признак длительности поездки trip duration. \n",
    "# Для этого вычислите интервал времени между временем окончания поездки (stoptime) и временем её начала (starttime) в секундах. \n",
    "# Рассчитайте среднее значение по новому столбцу — среднюю длительность поездки, а затем переведите её в секунды. \n",
    "# Ответ округлите до целого.\n",
    "data['starttime'] = pd.to_datetime(data['starttime'])\n",
    "data['stoptime'] = pd.to_datetime(data['stoptime'])\n",
    "data['trip duration'] = (data['stoptime'] - data['starttime'])\n",
    "print(data['trip duration'].mean().seconds)\n",
    "\n",
    "# ЗАДАНИЕ 6.11\n",
    "# Создайте «признак-мигалку» weekend, который равен 1, если поездка начиналась в выходной день (суббота или воскресенье),\n",
    "# и 0 — в противном случае. Выясните, сколько поездок начиналось в выходные.\n",
    "weekday = data['starttime'].dt.dayofweek\n",
    "data['weekend'] = weekday.apply(lambda x: 1 if x ==5 or x == 6 else 0)\n",
    "data['weekend'].sum()\n",
    "\n",
    "# ЗАДАНИЕ 6.12\n",
    "# Создайте признак времени суток поездки time_of_day. Время суток будем определять из часа начала поездки. Условимся, что:\n",
    "# поездка совершается ночью (night), если её час приходится на интервал от 0 (включительно) до 6 (включительно) часов;\n",
    "# поездка совершается утром (morning), если её час приходится на интервал от 6 (не включительно) до 12 (включительно) часов;\n",
    "# поездка совершается днём (day), если её час приходится на интервал от 12 (не включительно) до 18 (включительно) часов;\n",
    "# поездка совершается вечером (evening), если её час приходится на интервал от 18 (не включительно) до 23 часов (включительно).\n",
    "# Во сколько раз количество поездок, совершённых днём, больше, чем количество поездок, совёршенных ночью, \n",
    "# за представленный в данных период времени? Ответ округлите до целых.\n",
    "def get_time_of_day(time):\n",
    "    if 0 <= time <= 6:\n",
    "        return 'night'\n",
    "    elif 6 < time <= 12:\n",
    "        return 'morning'\n",
    "    elif 12 < time <= 18:\n",
    "        return 'day'\n",
    "    elif 18 < time <= 23:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'else'\n",
    "data['time_of_day'] = data['starttime'].dt.hour.apply(get_time_of_day)\n",
    "a = data[data['time_of_day'] == 'day'].shape[0]\n",
    "b = data[data['time_of_day'] == 'night'].shape[0]\n",
    "print(round(a / b))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
